---
title: "Clase 04: Movimiento Browniano"
author: "Juan Antonio Cuesta-Albetos"
date: 2020-04-21
categories: ["R"]
tags: ["Movimiento browniano", "Proceso Gaussiano"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(fda.usc)
```

Esta práctica tiene dos partes. En la primera (este fidhero) creamos los datos, en la segunda, se hace el programa para suavizar la curva utilizando el nucleo gaussiano.

### Parte 1: Ruido Blanco amortiguado

Empezamos por determinar la curva que vamos a utilizar Va a estar definida en el intervalo [0,1] N es el numero de puntos en los que la tenemos definida:

```{r}
N=101
t=seq(0,1,length.out = N)
```

Va a ser una curva de la forma:
$$X(t)= t^d(asin(2k\pi t)+(1-a)cos(2k\pi t)).$$
Definimos los siguientes parámetros:
```{r}
k=1;a=1;b=1;d=1

# Reparametrizamos
a=a/(a+b)
b=1-a
# generamos los datos
X=(a*sin(2*k*pi*t)+b*cos(2*k*pi*t))*(t^d)

plot(t,X,col="grey",type="l",xlab="",ylab="")
 abline(h=0,col="grey",lty=2)

```
Ahora cogemos una muestra de puntos en los que vamos a observar la curva con cierto error. Podemos coger la muestra en puntos elegidos al azar o de modo sistematico. En todo caso, n es el tamano muestral
```{r}
n=20
muestra=sort(sample(x=1:N,size=n,replace=FALSE))
muestra_t=t[muestra]
```


Las observaciones van a estar afectados de cierto error. Estos, a su vez, van a ser i.i.d. $N(0,\sigma^2)$
```{r}
muestra_X=X[muestra]+rnorm(n,mean = 0,sd =.03)

plot(muestra_t,muestra_X,pch=8,cex=.5,col="green",type = "l")
     points(muestra_t,muestra_X,pch=8,cex=.5)
     points(muestra_t,0*muestra_X,pch=4,cex=.5)
```

### Parte 2: Movimiento Browniano escalado

Se simulan n trayectorias de dos Brownianos:
   
   + Uno es estandard.
  
  + El otro es s veces un estandard.
  
  +  n es el numero de browniandos de cada tipo.
  
Se usa el hecho de que los incrementos del Browniano son normales independientes, con varianza igual al incremento.

```{r}
n=3
s=2
N=1000
I=seq(0,1,length.out = N+1)
```

Ahora calculamos el incremento, cuya raíz cuadrada es la desviación típica de los datos
```{r}
delta=I[2]-I[1]
Xs = delta^.5*cbind(rep(0,n),matrix(rnorm(N*n),nrow=n))
Ys = delta^.5*cbind(rep(0,n),matrix(s*rnorm(N*n),nrow=n))
color = 0
#Acumulados
B=Xs;Bs=Ys
for ( i in 1:n){
  B[i,] =  cumsum(Xs[i,])
  Bs[i,] = cumsum(Ys[i,])
}

plot(x = c(0,1),y = c(min(c(B,Bs)),max(c(B,Bs))),col= 0,xlab="",ylab="",
     main=paste0("Trayectorias de Brownianos. Unos estandard. Otros= ", s,"B"))
abline(h=0,col="grey")
for (i in 1:n){
  color=color+1
  lines(I,B[i,],col=color)
  color=color+1
  lines(I,Bs[i,],col=color)
}

```


De acuerdo con la teoría, debería ser SENCILLISIMO identificar los tres de cada clase
```{r}
plot(x = c(0,1),y = c(min(c(B,Bs)),max(c(B,Bs))),col= 0,xlab="",ylab="",
     main=paste0("Trayectorias de Brownianos. Unos estandard. Otros= ", s,"B"))
abline(h=0,col="grey")
for (i in 1:n){
  lines(I,B[i,],col="red")
  lines(I,Bs[i,],col="blue")
}
legend("bottomleft", legend = c(paste0("s=",1),paste0("s=",s)), col = c("red","blue"), 
       cex = 1, lwd = c(1,1),text.col = c("red","blue"))
```


Sin embargo, es muy facil distinguirlos si usamos la suma de los cuadrados de sus incrementos
```{r}
suma.cuadrados=rep(0,2*n)
for (i in 1:n){
  suma.cuadrados[i]=sum(Xs[i,]^2)
  suma.cuadrados[2*n-i+1]=sum(Ys[i,]^2)
}
round(suma.cuadrados,3)

```

