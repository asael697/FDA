---
title: 'Clase 06: Clasificacon de datos funcionales'
author: "Juan Antonio Cuesta-Albertos"
date: 2020-04-27
tags: ["clasificacion","profundidades","datos funcionales"]
---



<p>Aquí hacemos clasificación de datos funcionales, utilizamos las librerías:</p>
<ul>
<li><p>fda.usc</p></li>
<li><p>depth</p></li>
<li><p>matrixcalc</p></li>
</ul>
<p>Empezamos por cargar los datos phoneme que contienen 500 ondas producidas al pronuncias los sonidos ingleses “sh”, “iy”, “dcl”, “aa”, “ao”, 100 de cada uno hay 250 casos (50 de cada) en la training sample y otros tantos en la test sample.</p>
<pre class="r"><code>library(fda.usc)
library(depth)
library(matrixcalc)

data(phoneme)
names(phoneme)
## [1] &quot;learn&quot;      &quot;test&quot;       &quot;classlearn&quot; &quot;classtest&quot;
sonidos = c(&quot;sh&quot;, &quot;iy&quot;, &quot;dcl&quot;, &quot;aa&quot;, &quot;ao&quot;)</code></pre>
<p>Empezamos por dibujar los datos. Como son demasiados, elegimos una muestra de 25</p>
<pre class="r"><code>par(mfrow = c(2,1))
plot(phoneme[[&quot;learn&quot;]],col=phoneme$classlearn)
legend(&quot;bottomleft&quot;, legend = sonidos, col = 1:5,  lwd = 1,ncol=2)

muestra=50*c(1:5)
plot(phoneme[[&quot;learn&quot;]][muestra],col=phoneme$classlearn[muestra])
legend(&quot;bottomleft&quot;, legend = sonidos, col = 1:5,  lwd = 1,ncol=2)</code></pre>
<p><img src="/post/2020-04-28-06-Clasificacion_files/figure-html/unnamed-chunk-2-1.png" width="70%" style="display: block; margin: auto;" /></p>
<p>Seleccionamos los datos de la training y la test samples junto con sus etiquetas. También cogemos los nombres de los sonidos</p>
<pre class="r"><code>funct.phon.learn = phoneme[[&quot;learn&quot;]]
label.phon.learn = phoneme[[&quot;classlearn&quot;]]
funct.phon.test = phoneme$test
label.phon.test = phoneme[[&quot;classtest&quot;]]</code></pre>
<div id="clasificación-no-paramétrica." class="section level2">
<h2>Clasificación no paramétrica.</h2>
<p>Vamos a probar con 11 ventanas. El resto de parámetros son las opciones defecto de la función correspondiente.</p>
<pre class="r"><code>h = 9:19
out.np = classif.np(label.phon.learn,funct.phon.learn,h = h)

summary(out.np)
##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## y
##    1    2    3    4    5 
## 1.00 1.00 0.96 0.78 0.78 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##      1  2  3  4  5
##   1 50  0  0  0  0
##   2  0 50  0  0  0
##   3  1  1 48  0  0
##   4  0  0  0 39 11
##   5  0  0  1 10 39
## 
## -Vector of probability of correct classification
##     by banwidth (h):
##     9    10    11    12    13    14    15    16    17    18    19 
## 0.896 0.896 0.892 0.896 0.900 0.904 0.904 0.904 0.900 0.892 0.892 
## 
## -Optimal bandwidth: h.opt= 14 with highest probability of
## correct classification: max.prob= 0.904 
## 
## -Probability of correct classification:  0.904</code></pre>
<p>Ahora pasamos a ver que tal predice en la muestra test.</p>
<pre class="r"><code>pred.np = predict(out.np,funct.phon.test)</code></pre>
<p>La tabla siguiente contiene el resultado y luego ponemos algunos otros estadísticos</p>
<pre class="r"><code>result.np = table(pred.np,label.phon.test)

prop.correctos.np = diag(result.np)/50
names(prop.correctos.np) = sonidos

(Prop.Total.np = mean(prop.correctos.np))
## [1] 0.908</code></pre>
</div>
<div id="calsificacion-knn" class="section level2">
<h2>Calsificacion knn</h2>
<pre class="r"><code>k = seq(from = 1,to = 11,by = 2)
out.knn = classif.knn(label.phon.learn,funct.phon.learn,knn = k)
summary(out.knn)
##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## y
##    1    2    3    4    5 
## 1.00 0.98 0.98 0.80 0.80 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##      1  2  3  4  5
##   1 50  0  0  0  0
##   2  0 49  1  0  0
##   3  1  0 49  0  0
##   4  0  0  0 40 10
##   5  0  0  1  9 40
## 
## -Vector of probability of correct classification
##    by number of neighbors (knn):
##     1     3     5     7     9    11 
## 0.876 0.884 0.912 0.904 0.892 0.892 
## 
## -Optimal number of neighbors: knn.opt= 5 
## with highest probability of correct classification max.prob=  0.912 
## 
## -Probability of correct classification:  0.912</code></pre>
<p>Ahora pasamos a ver que tal predice en la muestra test.</p>
<pre class="r"><code>pred.knn = predict(out.knn,funct.phon.test)</code></pre>
<p>La tabla siguiente contiene el resultado y luego ponemos algunos otros estadísticos</p>
<pre class="r"><code>result.knn = table(pred.knn,label.phon.test)

prop.correctos.knn = diag(result.knn)/50
names(prop.correctos.knn) = sonidos

(Prop.Total.knn = mean(prop.correctos.knn))
## [1] 0.904</code></pre>
</div>
<div id="dd-classification-for-functional-data" class="section level2">
<h2>DD-classification for functional data</h2>
<pre class="r"><code>data(tecator)

ab = tecator$absorp.fdata
ab1 = fdata.deriv(ab,nderiv = 1)
ab2 = fdata.deriv(ab,nderiv = 2)

gfat = factor(as.numeric(tecator$y$Fat &gt;= 15))

# Train set
learn = 1:165

# 0 derivate
ab.learn = ab[learn]
ab.test = ab[-learn]

# 1 derivate
ab1.learn = ab1[learn]
ab1.test = ab1[-learn]

# 2 derivate
ab2.learn = ab2[learn]
ab2.test = ab2[-learn]

label.tec.learn = gfat[learn]
label.tec.test = gfat[-learn]</code></pre>
<div id="dd-classification-solo-dos-clases" class="section level3">
<h3>DD-classification solo dos clases</h3>
<pre class="r"><code>out0_0 = classif.DD(label.tec.learn,ab.learn,depth = &quot;mode&quot;,classif = &quot;np&quot;)</code></pre>
<p><img src="/post/2020-04-28-06-Clasificacion_files/figure-html/unnamed-chunk-11-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(out0_0)
##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## group
##         0         1 
## 0.6966292 0.8289474 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##      0  1
##   0 62 27
##   1 13 63
## 
## -Probability of correct classification:  0.7576</code></pre>
<pre class="r"><code>out0_1 = classif.DD(label.tec.learn,ab1.learn,depth = &quot;mode&quot;,classif = &quot;np&quot;)</code></pre>
<p><img src="/post/2020-04-28-06-Clasificacion_files/figure-html/unnamed-chunk-12-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(out0_1)
##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## group
##         0         1 
## 0.9775281 0.9605263 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##      0  1
##   0 87  2
##   1  3 73
## 
## -Probability of correct classification:  0.9697</code></pre>
<pre class="r"><code>out0_2 = classif.DD(label.tec.learn,ab2.learn,depth = &quot;mode&quot;,classif = &quot;np&quot;)</code></pre>
<p><img src="/post/2020-04-28-06-Clasificacion_files/figure-html/unnamed-chunk-13-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>summary(out0_2)
##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## group
##         0         1 
## 0.9438202 0.9868421 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##      0  1
##   0 84  5
##   1  1 75
## 
## -Probability of correct classification:  0.9636</code></pre>
<p>La tabla siguiente contiene el resultado y luego ponemos algunos otros estadísticos</p>
<pre class="r"><code>pred.DD.0 = predict(out0_0,ab.test)

result.DD.0 = table(pred.DD.0,label.tec.test)
Prop.Total.DD.0 = matrix.trace(result.DD.0)/sum(result.DD.0)
prop.correctos.DD.0 = 0*c(1:2)

for (i in 1:2){
  prop.correctos.DD.0[i] = result.DD.0[i,i]/length(label.tec.test[label.tec.test==(i-1)])
}

# Proporcion de acertados
names(prop.correctos.DD.0) = c(&quot;bajo&quot;,&quot;alto&quot;)
round(prop.correctos.DD.0,4)
##   bajo   alto 
## 0.6957 0.7407

# Total de aciertos
Prop.Total.DD.0
## [1] 0.72</code></pre>
<p>La tabla siguiente contiene el resultado y luego ponemos algunos otros estadísticos.</p>
<pre class="r"><code>pred.DD.1 = predict(out0_1,ab1.test)

result.DD.1 = table(pred.DD.1,label.tec.test)
Prop.Total.DD.1 = matrix.trace(result.DD.1)/sum(result.DD.1)
prop.correctos.DD.1 = 0*c(1:2)

for (i in 1:2){
  prop.correctos.DD.1[i] = result.DD.1[i,i]/length(label.tec.test[label.tec.test==(i-1)])
}

# Proporcion de acertados
names(prop.correctos.DD.1) = c(&quot;bajo&quot;,&quot;alto&quot;)
round(prop.correctos.DD.1,4)
##   bajo   alto 
## 0.9565 0.9259

# Total de aciertos
Prop.Total.DD.1
## [1] 0.94</code></pre>
<p>La tabla siguiente contiene el resultado y luego ponemos algunos otros estadísticos.</p>
<pre class="r"><code>pred.DD.2 = predict(out0_2,ab2.test)

result.DD.2 = table(pred.DD.2,label.tec.test)

Prop.Total.DD.2 = matrix.trace(result.DD.2)/sum(result.DD.2)
prop.correctos.DD.2 = 0*c(1:2)

for (i in 1:2){
  prop.correctos.DD.2[i] = result.DD.2[i,i]/length(label.tec.test[label.tec.test==(i-1)])
}

# Proporcion de acertados
names(prop.correctos.DD.2) = c(&quot;bajo&quot;,&quot;alto&quot;)
round(prop.correctos.DD.2,4)
##   bajo   alto 
## 0.9565 0.9630

# Total de aciertos
Prop.Total.DD.2
## [1] 0.96</code></pre>
<p>Ahora aplicamos el DD-classification en un caso con mas de dos clases:</p>
<pre class="r"><code>data(phoneme)

label.phon.learn = as.numeric(phoneme[[&quot;classlearn&quot;]]) - 1

DD.phon.1D = classif.DD(label.phon.learn,funct.phon.learn,depth = &quot;mode&quot;,classif = &quot;np&quot;)</code></pre>
<p><img src="/post/2020-04-28-06-Clasificacion_files/figure-html/unnamed-chunk-17-1.png" width="70%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>
summary(DD.phon.1D)
##      - SUMMARY - 
## 
## -Probability of correct classification by group (prob.classification):
## group
##    0    1    2    3    4 
## 0.98 1.00 0.92 0.78 0.82 
## 
## -Confusion matrix between the theoretical groups (by rows)
##   and estimated groups (by column) 
##    
##      0  1  2  3  4
##   0 49  1  0  0  0
##   1  0 50  0  0  0
##   2  0  4 46  0  0
##   3  0  0  0 39 11
##   4  0  0  1  8 41
## 
## -Probability of correct classification:  0.9</code></pre>
<p>La tabla siguiente contiene el resultado y luego ponemos algunos otros estadísticos.</p>
<pre class="r"><code>pred.DD.phon.1D = as.numeric(predict(DD.phon.1D,funct.phon.test))

result.DD.phon.1D = table(pred.DD.phon.1D,label.phon.test)
prop.correctos.DD.phon.1D = diag(result.DD.phon.1D)/50

names(prop.correctos.DD.phon.1D) = sonidos
prop.correctos.DD.phon.1D
##   sh   iy  dcl   aa   ao 
## 1.00 0.98 1.00 0.78 0.82

Prop.Total.DD.phon.1D = mean(prop.correctos.DD.phon.1D)
Prop.Total.DD.phon.1D
## [1] 0.916

resultados_clasif_fonemas = c(Prop.Total.np,Prop.Total.knn,Prop.Total.DD.phon.1D)
names(resultados_clasif_fonemas) = c(&quot;Kernel&quot;,&quot;kNN&quot;,&quot;DD-class. Fraiman_Muniz&quot;)

print(&quot;los resultados han sido:&quot;)
## [1] &quot;los resultados han sido:&quot;
resultados_clasif_fonemas
##                  Kernel                     kNN DD-class. Fraiman_Muniz 
##                   0.908                   0.904                   0.916</code></pre>
</div>
</div>
